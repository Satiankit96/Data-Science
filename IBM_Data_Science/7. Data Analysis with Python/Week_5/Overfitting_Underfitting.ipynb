{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8b0c325",
   "metadata": {},
   "source": [
    "### Underfitting The data \n",
    "We have chosen a lower degree model which is insuffiucient to draw a complex model \n",
    "Basically choosing a lower degree function than what is required "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36849094",
   "metadata": {},
   "source": [
    "### Over Fitting the data \n",
    "\n",
    "The model is of a higher degree than needed.\n",
    "More often than not. It will fit in some noise in the data as well.\n",
    "\n",
    "\n",
    "###### The picture below shows us two things.\n",
    "- Higher the order of the data, less the training error.\n",
    "- But this error will increase if a much higher degree is chosen.\n",
    "\n",
    "- basically find the sweet spot\n",
    "\n",
    "![](Under_Over.png)\n",
    "\n",
    "\n",
    "After we select the best order of the polynomial.\n",
    "We will still have some error.\n",
    "\n",
    "##### y = m(x) + Noise \n",
    "\n",
    "![](noise.png)\n",
    "\n",
    "\n",
    "# Calculating the best order for evaluation \n",
    "\n",
    "#### Value of the R^2 when it is closest to 1 is the best order.\n",
    "\n",
    "In the exaple below 3 is the best order function to calculate the model.\n",
    "\n",
    "![](r_Square.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81730c8d",
   "metadata": {},
   "source": [
    "## Ridge Regression \n",
    "\n",
    "This is used to tackle overfitting. We chose an alpha, which reduces the noise that could have been introduced by over or under fitting.\n",
    "\n",
    "#### ridge_model = Ridge(alpha=1.0)  # alpha is the regularization strength, you can adjust it\n",
    "\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "\n",
    "We use each value of alpha and calculate the value of r^2. Post that we choose the value of r^2 that is closest to 1.\n",
    "![](choosing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1fa246",
   "metadata": {},
   "source": [
    "## Grid Search \n",
    "\n",
    "Alpha is one of the hyper parameters. \n",
    "Objective is to choose the parameter that reduces the error.\n",
    "Scikit-learn has a means of automatically iterating over these hyperparameters using cross-validation called grid search.\n",
    "\n",
    "Step 1 - Training - Train the model with each hyperparameter.\n",
    "Step 2 - Validation - USe the parameter with least error and use that model.\n",
    "Step 3 - Test - test the model performance using the test data.\n",
    "\n",
    "Parameters \n",
    "1. Normalize\n",
    "2. Alpha \n",
    "\n",
    "![](Grid.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea28c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
